{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imporatations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: cohere in c:\\users\\newtek\\anaconda3\\lib\\site-packages (5.13.12)\n",
      "Requirement already satisfied: fastavro<2.0.0,>=1.9.4 in c:\\users\\newtek\\anaconda3\\lib\\site-packages (from cohere) (1.10.0)\n",
      "Requirement already satisfied: httpx>=0.21.2 in c:\\users\\newtek\\anaconda3\\lib\\site-packages (from cohere) (0.27.0)\n",
      "Requirement already satisfied: httpx-sse==0.4.0 in c:\\users\\newtek\\anaconda3\\lib\\site-packages (from cohere) (0.4.0)\n",
      "Requirement already satisfied: pydantic>=1.9.2 in c:\\users\\newtek\\anaconda3\\lib\\site-packages (from cohere) (2.10.6)\n",
      "Requirement already satisfied: pydantic-core<3.0.0,>=2.18.2 in c:\\users\\newtek\\anaconda3\\lib\\site-packages (from cohere) (2.27.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.0.0 in c:\\users\\newtek\\anaconda3\\lib\\site-packages (from cohere) (2.32.2)\n",
      "Requirement already satisfied: tokenizers<1,>=0.15 in c:\\users\\newtek\\anaconda3\\lib\\site-packages (from cohere) (0.21.0)\n",
      "Requirement already satisfied: types-requests<3.0.0,>=2.0.0 in c:\\users\\newtek\\anaconda3\\lib\\site-packages (from cohere) (2.32.0.20241016)\n",
      "Requirement already satisfied: typing_extensions>=4.0.0 in c:\\users\\newtek\\anaconda3\\lib\\site-packages (from cohere) (4.12.2)\n",
      "Requirement already satisfied: anyio in c:\\users\\newtek\\anaconda3\\lib\\site-packages (from httpx>=0.21.2->cohere) (4.2.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\newtek\\anaconda3\\lib\\site-packages (from httpx>=0.21.2->cohere) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\newtek\\anaconda3\\lib\\site-packages (from httpx>=0.21.2->cohere) (1.0.2)\n",
      "Requirement already satisfied: idna in c:\\users\\newtek\\anaconda3\\lib\\site-packages (from httpx>=0.21.2->cohere) (3.7)\n",
      "Requirement already satisfied: sniffio in c:\\users\\newtek\\anaconda3\\lib\\site-packages (from httpx>=0.21.2->cohere) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\newtek\\anaconda3\\lib\\site-packages (from httpcore==1.*->httpx>=0.21.2->cohere) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\newtek\\anaconda3\\lib\\site-packages (from pydantic>=1.9.2->cohere) (0.6.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\newtek\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->cohere) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\newtek\\anaconda3\\lib\\site-packages (from requests<3.0.0,>=2.0.0->cohere) (2.2.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\newtek\\anaconda3\\lib\\site-packages (from tokenizers<1,>=0.15->cohere) (0.28.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\newtek\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\newtek\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (2024.3.1)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\newtek\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\newtek\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (6.0.1)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\newtek\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (4.66.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\newtek\\anaconda3\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub<1.0,>=0.16.4->tokenizers<1,>=0.15->cohere) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install cohere --upgrade\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cohere\n",
    "API_KEY = 'rY76EgrEdNJQRAWU707DXcpnxWiiEFQzfOEpdISt'\n",
    "co = cohere.ClientV2(API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trying out Cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id='a6414643-578e-4ab4-bb3d-6f43dfe2730a' finish_reason='COMPLETE' prompt=None message=AssistantMessageResponse(role='assistant', tool_calls=None, tool_plan=None, content=[TextAssistantMessageResponseContentItem(type='text', text='Hello! How can I help you today?')], citations=None) usage=Usage(billed_units=UsageBilledUnits(input_tokens=3.0, output_tokens=9.0, search_units=None, classifications=None), tokens=UsageTokens(input_tokens=196.0, output_tokens=9.0)) logprobs=None\n"
     ]
    }
   ],
   "source": [
    "import cohere\n",
    "\n",
    "co = cohere.ClientV2(API_KEY)\n",
    "response = co.chat(\n",
    "    model=\"command-r-plus\", \n",
    "    messages=[{\"role\": \"user\", \"content\": \"hello world!\"}]\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding a cleaning generation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cohere_response(content: str):\n",
    "    API_KEY = 'rY76EgrEdNJQRAWU707DXcpnxWiiEFQzfOEpdISt'\n",
    "    co = cohere.ClientV2(API_KEY)\n",
    "   \n",
    "    messages = [{\"role\": \"user\", \"content\": content}]\n",
    "    chat_response = co.chat(model=\"command-r-plus\", messages=messages)\n",
    "    \n",
    "    if hasattr(chat_response, 'message') and hasattr(chat_response.message, 'content'):\n",
    "        for item in chat_response.message.content:\n",
    "            if hasattr(item, 'type') and item.type == 'text':\n",
    "                return item.text\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm an AI chatbot, so I don't have feelings, but I'm here to assist you with any questions or tasks you may have. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "# Try it out with the simple msg \"chahwelek\"\n",
    "response_text = get_cohere_response(\"hi how are you today!\")\n",
    "print(response_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Category(Enum):\n",
    "    BUG = 'bug report'\n",
    "    TECH = 'technical difficulties '\n",
    "    FEAT = 'feature requests'\n",
    "    MISC= 'miscellaneous '\n",
    "\n",
    "#outtput\n",
    "class ResultRequest(BaseModel):\n",
    "    category : Category\n",
    "    summary: str\n",
    "    extracted_data: str\n",
    "    \n",
    "#input\n",
    "class SupportRequest(BaseModel):\n",
    "    id: int\n",
    "    name: str\n",
    "    organization: str\n",
    "    text: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prompt0 = \"You are a customer service agent working in IT, you receive support requests and provide technical support\"\n",
    "PromptCateg = \"\"\"\"There are 4 categories of a support request: bug report or technical difficulties or feature requests or miscellaneous, tell me which one\n",
    " is this one (only name the category): \"\"\"\n",
    "promptSummary = \"give me a concise summary of this support request: \"\n",
    "promptDataBug = \"\"\"As the support request in this case is a bug report, extract elements such as error codes, affected features/pages,\n",
    "and triggering actions from this request only:\"\"\"\n",
    "promptDataTech = \"\"\"As the support request in this case is a technical difficulty, Extract details such as connection issues or\n",
    "performance issues, or if the client has any difficulties navigating the platform in general from this request only:\"\"\"\n",
    "promptDataFeat = \"\"\"As the support request in this case is a feature request, Extract the name of the requested feature and any\n",
    "context indicating urgency (low, medium, high) or benefits from this request only:  \"\"\"\n",
    "promptDataMisc = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature request.\n"
     ]
    }
   ],
   "source": [
    "response_text = get_cohere_response(Prompt0 + PromptCateg + \"I am having trouble with the platform, I need a new feature that does such and such\")\n",
    "print(response_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lilttle strs comparison function for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import SequenceMatcher\n",
    "\n",
    "def most_similar(target, options):\n",
    "    return max(options, key=lambda option: SequenceMatcher(None, target, option).ratio())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "helo world\n"
     ]
    }
   ],
   "source": [
    "target= \"hello world\"\n",
    "strs = [\"hello\", \"world\", \"helo world\", \"hello wrld\", \"goodbye world\"]\n",
    "best_match = most_similar(target, strs)\n",
    "print(best_match)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_support_request(support_request: SupportRequest) -> ResultRequest:\n",
    "    \n",
    "    # used these below cz didnt want to turn to cosine similarity and embeddings\n",
    "    L = [str(Category.BUG), str(Category.FEAT), str(Category.TECH), str(Category.MISC)]\n",
    "    category_map = {\n",
    "    str(Category.BUG): Category.BUG,\n",
    "    str(Category.FEAT): Category.FEAT,\n",
    "    str(Category.TECH): Category.TECH,\n",
    "    str(Category.MISC): Category.MISC,\n",
    "}\n",
    "\n",
    "    categ = get_cohere_response(Prompt0 + PromptCateg + support_request.text)\n",
    "    category_str = most_similar(categ, L)\n",
    "    category = category_map[category_str]  # Convert back to Category\n",
    "\n",
    "    summary = get_cohere_response(Prompt0 + promptSummary + support_request.text )\n",
    "\n",
    "    extracted_data = '' #had to initialize it cz it wouldnt work otherwise\n",
    "    \n",
    "    if category == Category.BUG:\n",
    "        extracted_data = get_cohere_response(Prompt0 + promptDataBug + support_request.text )\n",
    "    elif category == Category.TECH:\n",
    "        extracted_data = get_cohere_response(Prompt0 + promptDataTech + support_request.text )\n",
    "    elif category == Category.FEAT:\n",
    "        extracted_data = get_cohere_response(Prompt0 + promptDataFeat + support_request.text )\n",
    "    elif category == Category.MISC:\n",
    "        extracted_data = get_cohere_response('')\n",
    "\n",
    "    return ResultRequest(category=category, summary=summary, extracted_data=extracted_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sick"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category=<Category.BUG: 'bug report'> summary='A customer has reported a bug in the system. They need assistance in identifying and resolving the issue.' extracted_data='No error codes, affected features/pages, or triggering actions were explicitly mentioned in the bug report. However, the user states that they \"have a bug in the system,\" indicating a potential issue with the software or application as a whole.'\n"
     ]
    }
   ],
   "source": [
    "# Exemplef\n",
    "support_request = SupportRequest(id=1, name=\"John Doe\", organization=\"Acme Corp\", text=\"I have a bug in the system.\")\n",
    "result_request = process_support_request(support_request)\n",
    "print(result_request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
